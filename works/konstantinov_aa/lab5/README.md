# Лабораторная работа №5: Детекция объектов (RetinaNet) на TensorRT

## Описание задачи
Целью работы является реализация высокопроизводительного инференса нейросети RetinaNet-R50 для детектирования объектов в видеопотоке. Реализация поддерживает квантованную модель (INT8) и два режима работы:
1. **End-to-End (Plugin Mode):** Использование встроенных плагинов TensorRT для NMS.
2. **Raw Mode (Manual CUDA):** Ручная реализация постпроцессинга (декодирование координат, фильтрация по порогу и NMS) на языке CUDA.

## Функциональные возможности
- Загрузка и обработка видеофайлов различных форматов (MP4, AVI) через OpenCV.
- Инференс модели RetinaNet-R50 с использованием TensorRT 10.x.
- Ручной постпроцессинг на GPU:
    - Динамическая генерация анкоров (On-the-fly) в CUDA-ядре.
    - Параллельное декодирование BBox и фильтрация по Confidence Threshold.
    - Параллельный Non-Maximum Suppression (NMS) с использованием библиотеки Thrust.
- Отрисовка результатов: bounding boxes, названия классов и score.
- Сохранение обработанного видео в файл.

## Экспорт и подготовка модели

### 1. Экспорт модели (`scripts/export_model.py`)
Скрипт экспортирует предварительно обученную модель **RetinaNet-ResNet50-FPN** из библиотеки `torchvision`.
- **Почему RetinaNet?** Это проверенная архитектура Single-Stage Detector (SSD), которая обеспечивает отличный баланс между скоростью и точностью. Использование FPN (Feature Pyramid Network) позволяет эффективно детектировать объекты разных масштабов.
- **Процесс:** Скрипт загружает веса COCO (DEFAULT), создает "фиктивный" входной тензор и трассирует модель в формат ONNX (opset 18). Также автоматически извлекаются и сохраняются метки классов в `labels.txt`.

### 2. Квантование в INT8 (`quantize_int8.bat` / `.sh`)
- Используется утилита `trtexec`.
- Флаги `--int8 --fp16` включают режим пониженной точности. TensorRT автоматически выбирает оптимальные ядра (kernels) для каждого слоя, используя INT8 там, где это возможно, и откатываясь к FP16/FP32 для сохранения точности.
- Это позволяет ускорить инференс в 2-4 раза на поддерживаемых GPU (например, NVIDIA Turing, Ampere и новее) по сравнению с FP32.

## Требования
- NVIDIA GPU с поддержкой CUDA (Compute Capability 6.1+).
- CUDA Toolkit 12.x или выше.
- TensorRT 10.x.
- OpenCV 4.x.
- CMake 3.18+.

## Структура проекта
- `src/` — исходный код проекта (C++, CUDA).
- `models/` — ONNX модели, скомпилированные engine-файлы и файлы меток (labels.txt).
- `samples/` — примеры входных видеофайлов и результатов.
- `scripts/` — скрипты для экспорта и квантования модели.
- `CMakeLists.txt` — конфигурация сборки.

## Инструкция по сборке и запуску

### Сборка
```bash
mkdir build && cd build
cmake ..
cmake --build . --config Release
```

### Запуск
Программа принимает три обязательных аргумента: путь к engine-файлу, путь к входному видео и путь для сохранения результата.

```bash
# Пример запуска стандартной модели
./retinanet_det models/retinanet.engine samples/test.mp4 output.mp4

# Пример запуска INT8 модели
./retinanet_det models/retinanet_int8.engine samples/test.mp4 samples/output_int8.mp4
```

*Примечание: Файл labels.txt должен находиться в той же папке, что и .engine файл.*

## Результаты и бенчмарки
Тестирование проводилось на модели RetinaNet-R50 (640x640) с использованием Raw Mode постпроцессинга.

### Пример результата
```text
Video: samples/test.mp4 (1920x1080, 25 FPS)
Total Processing Time: 16.3801 sec
Detected Objects: 1561
Result: samples/output_int8.mp4
```
Программа успешно фильтрует детекции по порогу 0.5 и корректно отрисовывает 80 классов датасета COCO.

## Оптимизации
- **Constant Memory:** Параметры уровней FPN хранятся в константной памяти для ускорения доступа в CUDA-ядрах.
- **Shared Memory / Atomics:** Использование атомарных операций для сбора кандидатов в ядрах фильтрации.
- **Thrust:** Использование высокооптимизированных алгоритмов сортировки для подготовки данных к NMS.
